#version 450

// modified version of https://github.com/m-schuetz/ieeevr_2019_clod/blob/master/pointcloud_clod.vs
// original from
// author: Markus Schütz
// license: MIT license (https://opensource.org/licenses/MIT)

// Source for paper: "Real-Time Continuous Level of Detail Rendering of Point Clouds"
// Markus Schütz, Katharina Krösl, Michael Wimmer
// IEEE VR 2019, March, Osaka

//***** begin interface of view.glsl **********************************/
mat4 get_modelview_matrix();
mat4 get_projection_matrix();
mat4 get_modelview_projection_matrix();
mat4 get_inverse_modelview_matrix();
mat4 get_inverse_modelview_projection_matrix();
mat3 get_normal_matrix();
mat3 get_inverse_normal_matrix();
//***** end interface of view.glsl ***********************************/

layout(location = 0) in vec3 position; //position in world coordinates
//layout(location = 1) in vec4 color; //level in alpha channel
layout(location = 1) in uint color_rgba8; //level in alpha channel

uniform float CLOD;
uniform float scale;
uniform float spacing; //root_spacings
uniform float pointSize;
uniform float minMilimeters;
uniform vec2 screenSize;
uniform vec4 pivot;
uniform mat4 transform;

out vec3 vColor;
out float vPointSize;
out float vRadius;
out float vLinearDepth;


float rand(float n){
	return fract(cos(n) * 123456.789);
}


vec4 rgba_from_int(const uint col){
	vec4 re;
	re.a = float((col&0xFF000000) >> 24 ) / 255.0;
	re.b = float((col&0x00FF0000) >> 16 ) / 255.0;
	re.g = float((col&0x0000FF00) >> 8 ) / 255.0;
	re.r = float(col&0x000000FF) / 255.0;
	return re;
}

void main() {
	mat4 centralTransform = transform;
	vec4 pos = transform * vec4(position.xyz, 1.0);
	vec4 color = rgba_from_int(color_rgba8);

	gl_Position = pos;

	vec4 projected = gl_Position / gl_Position.w;

	vec4 centralProjected = centralTransform * vec4(position.xyz, 1.0);
	centralProjected.xyz = centralProjected.xyz / centralProjected.w;

	vLinearDepth = gl_Position.w;

	vColor = color.rgb;

	vec3 worldPos = position.xyz;

	float d = distance(worldPos, pivot.xyz);
	float dc = length(centralProjected.xy); // distance to the center in normalized device coordinatespace
	
	float level = mod(color.a * 255, 128);
	float aRandom = rand(position.x + position.y + position.z);

	float pointSpacing = scale * spacing / pow(2, level + aRandom);

	// targetSpacing dependant on camera distance
	//float targetSpacing = (d * ssArgs.CLOD / 1000);

	// dependent on cam distance and distance to center of screen
	//float targetSpacing = (d * ssArgs.CLOD) / (1000 * max(1 - 0.7 * dc , 0.3));
	float targetSpacing = (d * CLOD) / (1000 * max(1 - 0.7 * dc , 0.3));

	// reduce density away from center with the gaussian function
	// no significant improvement over 1 / (d - dc), so we've settled with the simpler one
	//float sigma = 0.4;
	//float gbc = (1 / (sigma * sqrt(2 * 3.1415))) * exp(-0.5 * pow( dc / sigma, 2.0 ));
	//targetSpacing = (1. * d * ssArgs.CLOD) / (1000 * gbc);

	float minPixels = 1;
	float maxPixels = 80;
	float sizeMultiplier = 1 * pointSize;

	float minMilimeters = scale * minMilimeters / sizeMultiplier;

	{ // point size based on target spacing
		float ws = max(targetSpacing, minMilimeters / 1000.0);

		float l = sizeMultiplier * 2 * ws;
		//vec4 v1 = ssArgs.view * ssArgs.world * vec4(position.xyz, 1.0);
		vec4 v1 = get_modelview_matrix() * vec4(position.xyz, 1.0);
		vec4 v2 = vec4(v1.x + l, v1.y + l, v1.z, 1.0);

		vec4 vp1 = get_projection_matrix() * v1;
		vec4 vp2 = get_projection_matrix() * v2;

		vec2 vs1 = vp1.xy / vp1.w;
		vec2 vs2 = vp2.xy / vp2.w;

		float ds = distance(vs1, vs2);
		float dp = ds * screenSize.y;

		gl_PointSize = (dp / 1) * 1;

		gl_PointSize = clamp(gl_PointSize, minPixels, maxPixels);

		vRadius = ws;
	}

	{ // adjust point size within blend-in range
		float zeroAt = pointSpacing;
		float fullAt = 0.8 * pointSpacing;
		
		float u = (targetSpacing - fullAt) / (zeroAt - fullAt);
		u = 1 - clamp(u, 0, 1);

		gl_PointSize = gl_PointSize * u;
	}

	vPointSize = gl_PointSize;
	gl_PointSize = 10.0;
	//gl_PointSize *= 0.8;
}

